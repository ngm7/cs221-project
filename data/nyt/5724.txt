Facebook says that any such practice would violate its rules, which include contingencies for reviewing posts in unfamiliar languages. Justin Osofsky, a Facebook vice president who oversees these contracts, said any corner-cutting probably came from midlevel managers at outside companies acting on their own.

This hints at a deeper problem. Facebook has little visibility into the giant outsourcing companies, which largely police themselves, and has at times struggled to control them. And because Facebook relies on the companies to support its expansion, its leverage over them is limited.

One hurdle to reining in inflammatory speech on Facebook may be Facebook itself. The platform relies on an algorithm that tends to promote the most provocative content, sometimes of the sort the company says it wants to suppress.

Facebook could blunt that algorithm or slow the company’s expansion into new markets, where it has proved most disruptive. But the social network instills in employees an almost unquestioned faith in their product as a force for good.

When Ms. Su, the News Feed engineer, was asked if she believed research finding that more Facebook usage correlates with more violence, she replied, “I don’t think so.”

“As we have greater reach, as we have more people engaging, that raises the stakes,” she said. “But I also think that there’s greater opportunity for people to be exposed to new ideas.”

Still, even some executives hesitate when asked whether the company has found the right formula.

Richard Allan, a London-based vice president who is also a sitting member of the House of Lords, said a better model might be “some partnership arrangement” with “government involved in setting the standards,” even if not all governments can be trusted with this power.